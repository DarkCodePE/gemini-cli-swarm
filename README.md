# ğŸš€ Gemini CLI Adapter - Sistema ruv-FANN + SAFLA + SPARC

Un adaptador universal para Google's Gemini CLI que implementa la arquitectura modular de **ruvnet** con soporte completo para **SAFLA**, **SPARC**, modelos **Neuro-Divergentes** y runtime **WASM**.

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Tu AplicaciÃ³n / Claude Code              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           ğŸ¯ Swarm Orchestrator (MCP + SAFLA)              â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚    â”‚  Gemini CLI     â”‚   Claude Flow   â”‚   Otros LLMs   â”‚  â”‚
â”‚    â”‚   Adapter       â”‚    Adapter      â”‚   Adapters     â”‚  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           ğŸ§  CatÃ¡logo Neuro-Divergente (Especialistas)      â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚    â”‚      LSTM       â”‚     N-BEATS     â”‚  Transformers   â”‚  â”‚
â”‚    â”‚   (Secuencias)  â”‚  (Forecasting)  â”‚   (Lenguaje)    â”‚  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              âš¡ ruv-FANN Core Engine (Rust)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  ğŸŒ WASM Runtime Universal                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ CaracterÃ­sticas Principales

- **ğŸ”Œ Adaptador Universal**: Interfaz comÃºn para cualquier LLM usando el trait `CodeGenerationFlow`
- **ğŸ§  SelecciÃ³n Inteligente**: Modelos neuro-divergentes especializados para cada tipo de tarea
- **âš¡ SAFLA Methodology**: AnÃ¡lisis â†’ DiseÃ±o â†’ EjecuciÃ³n â†’ Aprendizaje adaptivo
- **ğŸ”„ Bucle de Refinamiento**: Generar â†’ Verificar â†’ Refinar automÃ¡ticamente
- **ğŸ“Š Monitoreo de Performance**: MÃ©tricas en tiempo real y optimizaciÃ³n continua
- **ğŸŒ Runtime WASM**: Portabilidad completa (navegador, servidor, edge, IoT)

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Prerrequisitos

```bash
# Instalar Rust
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# Instalar dependencias del sistema
cargo --version
```

### 2. Configurar Variables de Entorno

**OpciÃ³n A: Usando archivo .env (RECOMENDADO)**
```bash
# 1. Crear archivo de configuraciÃ³n
cp variables.example.txt .env

# 2. Editar .env con tu API key real
# Cambiar: GEMINI_API_KEY=tu_gemini_api_key_aqui
# Por: GEMINI_API_KEY=AIzaSy... (tu key real)
```

**OpciÃ³n B: Variables de entorno tradicionales**
```bash
# API Key de Gemini (requerida)
export GEMINI_API_KEY="tu_api_key_aqui"

# Para Vertex AI (opcional)
export GOOGLE_CLOUD_PROJECT="tu_proyecto_gcp"
export GOOGLE_CLOUD_LOCATION="us-central1"

# Para logging detallado
export RUST_LOG="info"
```

### 3. Compilar y Ejecutar

```bash
# Clonar y entrar al directorio
git clone <tu_repositorio>
cd mi_enjambre_ia

# Compilar el proyecto
cargo build --release

# Ejecutar la demostraciÃ³n
cargo run
```

## ğŸ¯ Uso del Sistema

### Ejemplo BÃ¡sico: GeneraciÃ³n de CÃ³digo

```rust
use mi_enjambre_ia::{
    adapters::AdapterConfig,
    swarm::{SwarmOrchestrator, SwarmConfig, TaskBuilder},
};
use std::collections::HashMap;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // 1. Configurar adaptador
    let mut adapter_configs = HashMap::new();
    adapter_configs.insert("gemini".to_string(), AdapterConfig {
        api_key: "tu_api_key".to_string(),
        timeout_seconds: 30,
        max_attempts: 3,
        enable_verification: true,
        // ... otros campos
    });

    // 2. Inicializar swarm
    let mut orchestrator = SwarmOrchestrator::new(SwarmConfig::default());
    orchestrator.initialize(adapter_configs).await?;

    // 3. Crear tarea
    let task = TaskBuilder::code_generation(
        "Crear una funciÃ³n que ordene un vector usando quicksort"
    );

    // 4. Ejecutar con SAFLA
    let result = orchestrator.execute_task(task).await;
    
    if result.success {
        println!("CÃ³digo generado: {}", result.result.unwrap().code);
    }

    Ok(())
}
```

### Ejemplo Avanzado: Forecasting con N-BEATS

```rust
// El sistema automÃ¡ticamente selecciona el modelo N-BEATS para tareas de predicciÃ³n
let forecasting_task = TaskBuilder::forecasting(
    "Predecir ventas de productos para los prÃ³ximos 3 meses usando datos histÃ³ricos"
);

let result = orchestrator.execute_task(forecasting_task).await;
// El sistema usarÃ¡ automÃ¡ticamente el modelo N-BEATS optimizado
```

## ğŸ§  Modelos Neuro-Divergentes Disponibles

| Modelo | EspecializaciÃ³n | Score | Casos de Uso |
|--------|----------------|-------|--------------|
| **LSTM** | Secuencias temporales | 0.85 | PredicciÃ³n de ventas, anÃ¡lisis de sensores IoT |
| **N-BEATS** | Forecasting avanzado | 0.92 | Demanda energÃ©tica, forecasting financiero |
| **Transformer** | Procesamiento de lenguaje | 0.88 | GeneraciÃ³n de cÃ³digo, anÃ¡lisis de documentos |
| **Custom FANN** | Tareas generales | 0.75 | ClasificaciÃ³n, regresiÃ³n, prototipado |

### SelecciÃ³n AutomÃ¡tica de Modelos

El sistema usa inteligencia artificial para seleccionar automÃ¡ticamente el mejor modelo:

```rust
// Para tareas de predicciÃ³n â†’ N-BEATS o LSTM
let task1 = "Predecir ventas del prÃ³ximo trimestre"; // â†’ N-BEATS

// Para tareas de cÃ³digo â†’ Transformer  
let task2 = "Generar una API REST en Rust"; // â†’ Transformer

// Para tareas generales â†’ Custom FANN
let task3 = "Clasificar datos de clientes"; // â†’ Custom FANN
```

## ğŸ“Š MetodologÃ­a SAFLA

El sistema implementa un ciclo completo de **AnÃ¡lisis â†’ DiseÃ±o â†’ EjecuciÃ³n â†’ Aprendizaje**:

### Fase 1: AnÃ¡lisis ğŸ”
- Analiza la tarea para seleccionar el adaptador Ã³ptimo
- Selecciona el modelo neuro-divergente mÃ¡s adecuado
- EvalÃºa requisitos de performance y calidad

### Fase 2: DiseÃ±o ğŸ¨  
- Crea prompts optimizados para el LLM seleccionado
- Configura parÃ¡metros de generaciÃ³n especÃ­ficos
- Prepara el pipeline de verificaciÃ³n

### Fase 3: EjecuciÃ³n âš¡
- Ejecuta el bucle "Generar â†’ Verificar â†’ Refinar"
- Monitorea performance en tiempo real
- Aplica optimizaciones dinÃ¡micas

### Fase 4: Aprendizaje ğŸ“ˆ
- Analiza resultados para futuras optimizaciones
- Actualiza estrategias adaptivas
- Mejora la selecciÃ³n de modelos

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Personalizar Adaptador

```rust
let custom_config = AdapterConfig {
    api_key: "tu_key".to_string(),
    base_url: Some("https://custom-endpoint.com".to_string()),
    timeout_seconds: 60,
    max_attempts: 5,
    enable_verification: true,
    project_id: Some("mi-proyecto".to_string()),
    location: Some("europe-west1".to_string()),
};
```

### Configurar Swarm

```rust
let swarm_config = SwarmConfig {
    max_concurrent_tasks: 4,
    default_adapter: "gemini".to_string(),
    enable_neural_selection: true,
    enable_adaptive_learning: true,
    performance_monitoring: true,
};
```

### Crear Modelo Personalizado

```rust
use mi_enjambre_ia::neuro_divergent::{ModelType, ModelSpec};

let custom_model = ModelSpec {
    model_type: ModelType::CustomFANN {
        layers: vec![10, 20, 15, 1],
        activation: ActivationType::SigmoidSymmetric,
        learning_rate: 0.001,
    },
    // ... otros campos
};
```

## ğŸŒ CompilaciÃ³n a WASM

El sistema estÃ¡ preparado para compilarse a WebAssembly:

```bash
# Instalar wasm-pack
curl https://rustwasm.github.io/wasm-pack/installer/init.sh -sSf | sh

# Compilar a WASM
wasm-pack build --target web --out-dir pkg

# Usar en el navegador
import init, { run_swarm } from './pkg/mi_enjambre_ia.js';
await init();
```

## ğŸ“ˆ Monitoreo y EstadÃ­sticas

```rust
// Obtener estadÃ­sticas del swarm
let stats = orchestrator.get_stats();
println!("Tasa de Ã©xito: {:.1}%", stats.success_rate * 100.0);
println!("Score promedio: {:.2}", stats.average_performance_score);
println!("Tareas completadas: {}", stats.successful_tasks);
```

## ğŸ” Troubleshooting

### Error: "GEMINI_API_KEY no encontrada"
```bash
# Configurar la API key
export GEMINI_API_KEY="tu_api_key_real"

# Verificar
echo $GEMINI_API_KEY
```

### Error de compilaciÃ³n con ruv-FANN
```bash
# Limpiar y recompilar
cargo clean
cargo build --release
```

### Modo de demostraciÃ³n
Si no tienes una API key, el sistema ejecutarÃ¡ en modo demostraciÃ³n mostrando todas las capacidades locales.

## ğŸ¤ Contribuir

1. Fork el repositorio
2. Crea una rama para tu feature: `git checkout -b feature/nueva-funcionalidad`
3. Commit tus cambios: `git commit -am 'Agregar nueva funcionalidad'`
4. Push a la rama: `git push origin feature/nueva-funcionalidad`
5. Crea un Pull Request

## ğŸ“ Licencia

Este proyecto estÃ¡ licenciado bajo la Licencia MIT - ver el archivo `LICENSE` para detalles.

## ğŸ™ Agradecimientos

- **ruvnet**: Por la arquitectura modular y la filosofÃ­a de diseÃ±o
- **SAFLA**: Por la metodologÃ­a de desarrollo sistemÃ¡tico  
- **SPARC**: Por las mejores prÃ¡cticas de ingenierÃ­a
- **ruv-FANN**: Por el motor de redes neuronales optimizado
- **Google**: Por la API de Gemini y las capacidades de Vertex AI

---

**Â¡La fÃ¡brica de IA inteligente estÃ¡ lista para funcionar! ğŸš€** 